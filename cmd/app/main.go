package main

import (
	"context"
	"cve-processor/config"
	"cve-processor/internal/cve"
	"cve-processor/internal/db"
	"fmt"
	"log"
	"net/http"
	"os"
	"os/signal"
	"sync"

	"github.com/IBM/sarama"
	"gorm.io/gorm"
)

var (
	offsetMap            sync.Map
	lastCommittedOffsets sync.Map
)

func main() {
	config, err := config.LoadConfig()
	if err != nil {
		log.Fatal("Error loading config:", err)
	}

	db := db.ConnectToPostgresDB(config)

	saramaConfig := sarama.NewConfig()
	saramaConfig.Net.SASL.Enable = true
	saramaConfig.Net.SASL.User = config.KafkaUsername
	saramaConfig.Net.SASL.Password = config.KafkaPassword
	saramaConfig.Net.SASL.Mechanism = sarama.SASLTypePlaintext

	go startHealthCheckServer(config, saramaConfig, db)

	// Consumer group configuration
	consumer := Consumer{
		ready: make(chan bool),
		db:    db,
	}
	ctx := context.Background()
	client, err := sarama.NewConsumerGroup(config.KafkaBrokers, config.KafkaGroupID, saramaConfig)
	if err != nil {
		log.Fatalf("Error creating consumer group client: %v", err)
	}

	go func() {
		for {
			if err := client.Consume(ctx, []string{config.KafkaTopic}, &consumer); err != nil {
				log.Fatalf("Error from consumer: %v", err)
			}
			if ctx.Err() != nil {
				return
			}
			consumer.ready = make(chan bool)
		}
	}()

	<-consumer.ready
	log.Println("Sarama consumer up and running!...")
	sigterm := make(chan os.Signal, 1)
	signal.Notify(sigterm, os.Interrupt)

	<-sigterm
	log.Println("Terminating: via signal")

	if err = client.Close(); err != nil {
		log.Fatalf("Error closing client: %v", err)
	}
}

type Consumer struct {
	ready chan bool
	db    *gorm.DB
}

// Setup is run at the beginning of a new session, before ConsumeClaim.
func (consumer *Consumer) Setup(sarama.ConsumerGroupSession) error {
	close(consumer.ready)
	return nil
}

// Cleanup is run at the end of a session, once all ConsumeClaim goroutines have exited.
func (consumer *Consumer) Cleanup(sarama.ConsumerGroupSession) error {
	return nil
}

// ConsumeClaim must start a consumer loop of ConsumerGroupClaim's Messages().
func (consumer *Consumer) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {
	for {
		select {
		case message := <-claim.Messages():
			// Store latest received offset in-memory
			offsetMap.Store(message.Partition, message.Offset)

			log.Printf("Message claimed: timestamp = %v, topic = %s, partition = %d, offset = %d",
				message.Timestamp, message.Topic, message.Partition, message.Offset)

			// Process the message here
			session.MarkMessage(message, "")
			messageID := fmt.Sprintf("Partition: %d, Offset: %d", message.Partition, message.Offset)
			err := cve.ProcessRecord(message.Value, consumer.db, messageID)
			if err != nil {
				log.Printf("Error processing CVE record: %v", err)
			}
		case <-session.Context().Done():
			// Remove rebalanced partition from in-memory map
			offsetMap.Delete(claim.Partition())
			lastCommittedOffsets.Delete(claim.Partition())
			return nil
		}
	}
}

func startHealthCheckServer(config *config.Config, saramaConfig *sarama.Config, db *gorm.DB) {
	http.HandleFunc("/liveness", func(w http.ResponseWriter, r *http.Request) {
		client, err := sarama.NewClient(config.KafkaBrokers, saramaConfig)
		if err != nil {
			w.WriteHeader(http.StatusInternalServerError)
			fmt.Fprintln(w, "Failed to create Kafka client")
			return
		}
		defer client.Close()
		// Database check
		psqlDB, err := db.DB()
		if err != nil {
			http.Error(w, "Database connection failed", http.StatusServiceUnavailable)
			return
		}

		ctx := context.Background()
		if err := psqlDB.PingContext(ctx); err != nil {
			http.Error(w, "Database ping failed", http.StatusServiceUnavailable)
			return
		}
		isHealthy := true
		offsetMap.Range(func(key, value interface{}) bool {
			partition := key.(int32)
			committedOffset := value.(int64)

			currentOffset, err := client.GetOffset(config.KafkaTopic, partition, sarama.OffsetNewest)
			if err != nil {
				log.Printf("Liveness check - Failed to get current offset for partition %d: %v", partition, err)
				isHealthy = false
				return false
			}

			log.Printf("Liveness check - partition: %d, current offset: %d, committed offset: %d", partition, currentOffset, committedOffset)

			// If current offset equals committed offset, there are no messages left to process
			if currentOffset == committedOffset || currentOffset == committedOffset+1 {
				log.Printf("Liveness check - Current and committed offset are equal, no messages left to process on the topic %v", config.KafkaTopic)
				return true
			}

			lastCommittedOffset, exists := lastCommittedOffsets.Load(partition)
			if exists && lastCommittedOffset.(int64) == committedOffset {
				log.Printf("Liveness check - Committed offset has not changed since the last run for partition %d", partition)
				isHealthy = false
				return false
			}

			// Update the last committed offset for the partition
			lastCommittedOffsets.Store(partition, committedOffset)

			return true
		})

		if isHealthy {
			w.WriteHeader(http.StatusOK)
			fmt.Fprintln(w, "Healthy")
		} else {
			w.WriteHeader(http.StatusInternalServerError)
			fmt.Fprintln(w, "Unhealthy")
		}
	})
	http.HandleFunc("/readiness", func(w http.ResponseWriter, r *http.Request) {
		client, err := sarama.NewClient(config.KafkaBrokers, saramaConfig)
		if err != nil {
			http.Error(w, "Kafka connection failed", http.StatusServiceUnavailable)
			return
		}
		defer client.Close()

		// Check if at least one broker is available
		brokers := client.Brokers()
		if len(brokers) == 0 {
			http.Error(w, "All Kafka brokers are down", http.StatusServiceUnavailable)
			return
		}
		// Check if the topic exists
		topics, err := client.Topics()
		if err != nil {
			http.Error(w, "Failed to fetch Kafka topics", http.StatusServiceUnavailable)
			return
		}

		topicExists := false
		for _, topic := range topics {
			if topic == config.KafkaTopic {
				topicExists = true
				break
			}
		}

		if !topicExists {
			http.Error(w, "Kafka topic does not exist", http.StatusServiceUnavailable)
			return
		}

		// Database readiness check
		psqlDB, err := db.DB()
		if err != nil {
			http.Error(w, "Database connection failed", http.StatusServiceUnavailable)
			return
		}

		ctx := context.Background()
		if err := psqlDB.PingContext(ctx); err != nil {
			http.Error(w, "Database ping failed", http.StatusServiceUnavailable)
			return
		}

		w.WriteHeader(http.StatusOK)
		w.Write([]byte("Ready"))
	})
	log.Fatal(http.ListenAndServe(":"+config.Port, nil))
}
